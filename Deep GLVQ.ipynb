{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92ef9a6-4972-4869-b552-6410b0b74f43",
   "metadata": {},
   "source": [
    "### Deep GLVQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d31163-cb71-4768-ab6f-4367a3730229",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8f36b1-ac13-402d-a909-e35153b7b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mnist_helpers import process_mnist_dataset\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklvq import GLVQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12305a60-a514-4018-af5e-6bc9cc38d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae86d6-8f3e-4b9b-a0c3-f4603656896d",
   "metadata": {},
   "source": [
    "##### Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b549747-266b-4db2-90c8-8841e90eeff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "validation_split = 0.2\n",
    "\n",
    "train_data,validation_data,test_data = process_mnist_dataset(batch_size,validation_split)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c63b52-5d4a-40f0-9696-da43b1513f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,n_dims_for_classif):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 392)\n",
    "        self.fc2 = nn.Linear(392, 194)\n",
    "        self.fc3 = nn.Linear(194, n_dims_for_classif)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(392)\n",
    "        self.bn2 = nn.BatchNorm1d(194)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)  \n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)  \n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "\n",
    "        x = self.fc3(x)  \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc34a1f-8b49-4f6b-a9db-46994699727f",
   "metadata": {},
   "source": [
    "##### GLVQ Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "710d9102-dab4-4fc0-81b3-36f9bd39abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def L_GLVQ(X, y, P, Py, gamma=0.4, epsilon=1e-8):\n",
    "    pairwise_distances = torch.cdist(X, P)  \n",
    "\n",
    "    same_class_mask = (Py == y.unsqueeze(1))\n",
    "    diff_class_mask = (Py != y.unsqueeze(1))\n",
    "\n",
    "    large_number = 1e9\n",
    "\n",
    "    d_plus = torch.where(same_class_mask, pairwise_distances, torch.full_like(pairwise_distances, large_number))\n",
    "    d_plus = torch.min(d_plus, dim=1).values  \n",
    "\n",
    "    d_minus = torch.where(diff_class_mask, pairwise_distances, torch.full_like(pairwise_distances, large_number))\n",
    "    d_minus = torch.min(d_minus, dim=1).values  \n",
    "\n",
    "    raw_loss = torch.sigmoid((d_plus - d_minus) / (d_plus + d_minus + epsilon))\n",
    "    \n",
    "    loss = torch.mean(torch.where(raw_loss > gamma, raw_loss - gamma, torch.zeros_like(raw_loss)))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b70c93-bae2-4747-a6cc-0089634f0448",
   "metadata": {},
   "source": [
    "###### Training Deep GLVQ Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35ea9af6-482c-4f19-8a61-1518bccb037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_acc(model,val_loader,fitted_glvq_object):\n",
    "\n",
    "    latents = []\n",
    "    labels = []\n",
    "\n",
    "    for batch_idx,(data,target) in enumerate(val_loader):\n",
    "\n",
    "        cur_latents = model(data).detach().numpy()\n",
    "        cur_labels = target.detach().numpy()\n",
    "\n",
    "        latents.extend(cur_latents)\n",
    "        labels.extend(cur_labels)\n",
    "\n",
    "    glvq_acc = fitted_glvq_object.score(latents,labels)\n",
    "\n",
    "\n",
    "    return glvq_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e53e303-d450-4091-95eb-e253e7e23fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims_for_classif = 10\n",
    "encoder = Encoder(n_dims_for_classif)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "n_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d61d353-7a81-4639-b646-4a60d575ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 40: 188it [01:09,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 validation accuracy: 0.89875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 40: 0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m latents_np \u001b[38;5;241m=\u001b[39m latents\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     28\u001b[0m targets_np \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 30\u001b[0m glvq\u001b[38;5;241m.\u001b[39mfit(latents_np,targets_np)\n\u001b[0;32m     32\u001b[0m P \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(glvq\u001b[38;5;241m.\u001b[39mprototypes_)\n\u001b[0;32m     33\u001b[0m Py \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(glvq\u001b[38;5;241m.\u001b[39mprototypes_labels_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklvq\\models\\_base.py:570\u001b[0m, in \u001b[0;36mLVQBaseClass.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# Before solve (handles initialization of things)\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_fit(X, y_index)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solver\u001b[38;5;241m.\u001b[39msolve(X, y_index, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# After solve (handles initialization of things that can only be done after fit)\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_fit(X, y_index)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklvq\\solvers\\_steepest_gradient_descent.py:193\u001b[0m, in \u001b[0;36mSteepestGradientDescent.solve\u001b[1;34m(self, data, labels, model)\u001b[0m\n\u001b[0;32m    190\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m labels[i_batch]\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Compute objective gradient\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m objective_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mgradient(model, batch, batch_labels)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Multiply each param by its given step_size\u001b[39;00m\n\u001b[0;32m    196\u001b[0m model\u001b[38;5;241m.\u001b[39mmul_step_size(step_size, objective_gradient)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklvq\\objectives\\_generalized_learning_objective.py:158\u001b[0m, in \u001b[0;36mGeneralizedLearningObjective.gradient\u001b[1;34m(self, model, data, labels)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient\u001b[39m(\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    119\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLVQBaseClass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    120\u001b[0m     data: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m    121\u001b[0m     labels: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the generalized learning objective's gradient with respect to the\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    prototype with a different label:\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     dist_same, dist_diff, i_dist_same, i_dist_diff \u001b[38;5;241m=\u001b[39m _compute_distance(\n\u001b[0;32m    159\u001b[0m         data, labels, model\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     discriminant_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminant(dist_same, dist_diff)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Pre-allocation, needs to be zero.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklvq\\objectives\\_generalized_learning_objective.py:248\u001b[0m, in \u001b[0;36m_compute_distance\u001b[1;34m(data, labels, model)\u001b[0m\n\u001b[0;32m    244\u001b[0m prototypes_labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprototypes_labels_\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Step 1: Compute distances between X and the model (how is depending on model and coupled\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# distance function)\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m distances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_distance(data, model)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Step 2: Find for all samples the distance between closest prototype with same label (d1)\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# and different label (d2). ii_same marks for all samples the prototype with the same label.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklvq\\distances\\_squared_euclidean.py:59\u001b[0m, in \u001b[0;36mSquaredEuclidean.__call__\u001b[1;34m(self, data, model)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     57\u001b[0m     distance_function \u001b[38;5;241m=\u001b[39m _nan_squared_euclidean\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cdist(data, model\u001b[38;5;241m.\u001b[39mprototypes_, distance_function)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\scipy\\spatial\\distance.py:3127\u001b[0m, in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3126\u001b[0m     cdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mcdist_func\n\u001b[1;32m-> 3127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cdist_fn(XA, XB, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   3129\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#standard GLVQ loss\n",
    "gamma = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for batch_idx,(data,target) in tqdm(enumerate(train_loader),desc = f'Epoch {epoch + 1} / {n_epochs}'):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        latents = encoder(data)\n",
    "\n",
    "        latents = (latents - torch.mean(latents,axis = 0)) / torch.std(latents, axis = 0)\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "\n",
    "            glvq = GLVQ(\n",
    "                distance_type=\"squared-euclidean\",\n",
    "                activation_type=\"sigmoid\",\n",
    "                activation_params={\"beta\": 1},\n",
    "                solver_type=\"steepest-gradient-descent\",\n",
    "                solver_params={\"max_runs\": 20, \"step_size\": 0.1},\n",
    "                prototype_n_per_class=8\n",
    "            )\n",
    "\n",
    "            latents_np = latents.detach().numpy()\n",
    "            targets_np = target.detach().numpy()\n",
    "\n",
    "            glvq.fit(latents_np,targets_np)\n",
    "\n",
    "            P = torch.Tensor(glvq.prototypes_)\n",
    "            Py = torch.Tensor(glvq.prototypes_labels_)\n",
    "\n",
    "        glvq_loss = L_GLVQ(\n",
    "            latents,target,P,Py,gamma = gamma\n",
    "        )\n",
    "\n",
    "        glvq_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    val_acc = get_val_acc(encoder,validation_loader,glvq)\n",
    "    print(f'Epoch {epoch + 1} validation accuracy: {val_acc}\\n')\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
